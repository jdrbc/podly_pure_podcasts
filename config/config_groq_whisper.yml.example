# Required openai settings for LLM processing (not used for transcription)
llm_api_key: sk-proj-XXXXXXXXXXXXXXXXXXXXXXXX
# Optional openai settings
# openai_base_url: http://127.0.0.1:11434/v1
# openai_timeout: 300
# openai_max_tokens: 4096
# openai_model: phi3:14b-medium-4k-instruct-q5_K_M

# if true then all new episodes will be whitelisted for download
automatically_whitelist_new_episodes: true

# limit the number episodes that podly will include from a new feed's archive
# this is helpful because some podcast clients will poll the download endpoint
# for every podcast (probably to get timestamp?) and this will cause podly to
# download every podcast; so by setting this to a small number it caps the number
# of podcasts podly will automatically whitelist in that scenario
# if you want to download old episodes you can whitelist them from the UI
# if automatically_whitelist_new_episodes overrides is false this setting is ignored
number_of_episodes_to_whitelist_from_archive_of_new_feed: 1

processing:
  system_prompt_path: config/system_prompt.txt
  user_prompt_template_path: config/user_prompt.jinja
  num_segments_to_input_to_prompt: 30

output:
  fade_ms: 3000
  min_ad_segement_separation_seconds: 60
  min_ad_segment_length_seconds: 14
  min_confidence: 0.8

# Groq Whisper configuration
whisper:
  whisper_type: groq
  api_key: gsk_XXXXXXXXXXXXXXXXXXXXXXXXXXXX
  model: whisper-large-v3-turbo
  language: en
  max_retries: 3
