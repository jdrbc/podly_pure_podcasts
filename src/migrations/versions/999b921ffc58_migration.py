"""migration

Revision ID: 999b921ffc58
Revises: 401071604e7b
Create Date: 2025-10-18 15:11:24.463135

"""

import sqlalchemy as sa
from alembic import op

# revision identifiers, used by Alembic.
revision = "999b921ffc58"
down_revision = "401071604e7b"
branch_labels = None
depends_on = None


def upgrade():
    # ### commands auto generated by Alembic - please adjust! ###
    bind = op.get_bind()
    inspector = sa.inspect(bind)
    existing_tables = set(inspector.get_table_names())

    # Create jobs_manager_run table only if it doesn't exist (makes migration idempotent)
    if "jobs_manager_run" not in existing_tables:
        op.create_table(
            "jobs_manager_run",
            sa.Column("id", sa.String(length=36), nullable=False),
            sa.Column(
                "status", sa.String(length=50), nullable=False, server_default="pending"
            ),
            sa.Column("trigger", sa.String(length=100), nullable=False),
            sa.Column("started_at", sa.DateTime(), nullable=True),
            sa.Column("completed_at", sa.DateTime(), nullable=True),
            sa.Column("total_jobs", sa.Integer(), nullable=False, server_default="0"),
            sa.Column("queued_jobs", sa.Integer(), nullable=False, server_default="0"),
            sa.Column("running_jobs", sa.Integer(), nullable=False, server_default="0"),
            sa.Column(
                "completed_jobs", sa.Integer(), nullable=False, server_default="0"
            ),
            sa.Column("failed_jobs", sa.Integer(), nullable=False, server_default="0"),
            sa.Column("context_json", sa.JSON(), nullable=True),
            sa.Column("previous_run_id", sa.String(length=36), nullable=True),
            sa.Column(
                "created_at",
                sa.DateTime(),
                nullable=False,
                server_default=sa.func.current_timestamp(),
            ),
            sa.Column(
                "updated_at",
                sa.DateTime(),
                nullable=False,
                server_default=sa.func.current_timestamp(),
            ),
            sa.PrimaryKeyConstraint("id"),
        )

    # Index on status for quick filtering (create only if missing)
    if "jobs_manager_run" in existing_tables:
        existing_indexes = {
            idx["name"] for idx in inspector.get_indexes("jobs_manager_run")
        }
    else:
        existing_indexes = set()

    if "ix_jobs_manager_run_status" not in existing_indexes:
        op.create_index(
            "ix_jobs_manager_run_status", "jobs_manager_run", ["status"], unique=False
        )

    # Add jobs_manager_run_id column and FK to processing_job only if column doesn't exist
    processing_cols = {col["name"] for col in inspector.get_columns("processing_job")}
    if "jobs_manager_run_id" not in processing_cols:
        with op.batch_alter_table("processing_job", schema=None) as batch_op:
            batch_op.add_column(
                sa.Column("jobs_manager_run_id", sa.String(length=36), nullable=True)
            )
            batch_op.create_index(
                batch_op.f("ix_processing_job_jobs_manager_run_id"),
                ["jobs_manager_run_id"],
                unique=False,
            )
            batch_op.create_foreign_key(
                "fk_processing_job_jobs_manager_run_id",
                "jobs_manager_run",
                ["jobs_manager_run_id"],
                ["id"],
            )

    with op.batch_alter_table("whisper_settings", schema=None) as batch_op:
        batch_op.drop_column("groq_initial_backoff")
        batch_op.drop_column("groq_backoff_factor")

    # ### end Alembic commands ###


def downgrade():
    # ### commands auto generated by Alembic - please adjust! ###
    bind = op.get_bind()
    inspector = sa.inspect(bind)
    existing_tables = set(inspector.get_table_names())

    with op.batch_alter_table("whisper_settings", schema=None) as batch_op:
        batch_op.add_column(
            sa.Column(
                "groq_backoff_factor",
                sa.FLOAT(),
                server_default=sa.text("'2.0'"),
                nullable=False,
            )
        )
        batch_op.add_column(
            sa.Column(
                "groq_initial_backoff",
                sa.FLOAT(),
                server_default=sa.text("'1.0'"),
                nullable=False,
            )
        )

    with op.batch_alter_table("processing_job", schema=None) as batch_op:
        # Only drop FK/index/column if they exist
        processing_cols = {
            col["name"] for col in inspector.get_columns("processing_job")
        }
        if "jobs_manager_run_id" in processing_cols:
            batch_op.drop_constraint(
                "fk_processing_job_jobs_manager_run_id", type_="foreignkey"
            )
            batch_op.drop_index(batch_op.f("ix_processing_job_jobs_manager_run_id"))
            batch_op.drop_column("jobs_manager_run_id")

    # Drop jobs_manager_run index and table if present
    if "jobs_manager_run" in existing_tables:
        # drop index if exists
        try:
            op.drop_index("ix_jobs_manager_run_status", table_name="jobs_manager_run")
        except Exception:
            # ignore if index doesn't exist
            pass
        op.drop_table("jobs_manager_run")

    # ### end Alembic commands ###
