# ===================
# --- Basic Setup ---
# ===================

# Podly will work out of the box with just a valid Groq key
# You can do more advanced setup with alternative models, local whisper
# or self hosting, ect below
GROQ_API_KEY=gsk_abcdefghjiklmnopqrstuvwxyz

# ======================
# --- Advanced Setup ---
# ======================

# ========================================
# --- LLM (OpenAI-compatible or proxy) ---
# ========================================

# Base URL is IGNORED when LLM_MODEL is provider-prefixed like the examples below:
# groq/openai/gpt-oss-120b  (Groq API)
# anthropic/claude-3.5-sonnet (Anthropic API)
# gemini/gemini-3-flash-preview (Google API)
# gemini/gemini-2.0-flash (Google API)

# Base URL is USED for:
# Unprefixed models like gpt-4o
# Self-hosted OpenAI-compatible endpoints
# LiteLLM proxy servers or local LLMs

LLM_API_KEY=sk-your-openai-or-compatible-key
LLM_MODEL=gpt-4o

# locally hosted endpoint
# OPENAI_BASE_URL=

# =========================
# --- Whisper selection ---
# =========================

# Choose: local | remote | groq
WHISPER_TYPE=groq

# Local Whisper
WHISPER_LOCAL_MODEL=base.en

# Remote Whisper (OpenAI-compatible)
WHISPER_REMOTE_API_KEY=
WHISPER_REMOTE_BASE_URL=https://api.openai.com/v1
WHISPER_REMOTE_MODEL=whisper-1
WHISPER_REMOTE_TIMEOUT_SEC=600
WHISPER_REMOTE_CHUNKSIZE_MB=24

# Groq Whisper
GROQ_WHISPER_MODEL=whisper-large-v3-turbo
GROQ_MAX_RETRIES=3

# ===============
# --- General ---
# ===============

SERVER_THREADS=1

# =====================
# --- Authentication ---
# =====================

# Set REQUIRE_AUTH=true to enable login for the web UI, feeds, and downloads
# REQUIRE_AUTH=true
# PODLY_ADMIN_USERNAME=podly_admin
# PODLY_ADMIN_PASSWORD=ChangeMe123!
# PODLY_SECRET_KEY=replace-with-a-strong-random-value
