# ===================
# --- Basic Setup ---
# ===================

# Podly will work out of the box with just a valid Groq key
# You can do more advanced setup with alternative models, local whisper
# or self hosting, ect below
GROQ_API_KEY=gsk_abcdefghjiklmnopqrstuvwxyz

# ======================
# --- Advanced Setup ---
# ======================

# ========================================
# --- LLM (OpenAI-compatible or proxy) ---
# ========================================

LLM_API_KEY=sk-your-openai-or-compatible-key
LLM_MODEL=gpt-4o

# locally hosted endpoint
# OPENAI_BASE_URL=

# =========================
# --- Whisper selection ---
# =========================

# Choose: local | remote | groq
WHISPER_TYPE=groq

# Local Whisper
WHISPER_LOCAL_MODEL=base.en

# Remote Whisper (OpenAI-compatible)
WHISPER_REMOTE_API_KEY=
WHISPER_REMOTE_BASE_URL=https://api.openai.com/v1
WHISPER_REMOTE_MODEL=whisper-1
WHISPER_REMOTE_TIMEOUT_SEC=600
WHISPER_REMOTE_CHUNKSIZE_MB=24

# Groq Whisper
GROQ_WHISPER_MODEL=whisper-large-v3-turbo
GROQ_MAX_RETRIES=3

# ===============
# --- General ---
# ===============

SERVER_THREADS=1